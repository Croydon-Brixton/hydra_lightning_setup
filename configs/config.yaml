name: test
load_from_checkpoint: null  # null to start from scratch
device: 
seed: 5721 # Random seed.

transforms:
  filter_pocket:
    radius: 12
  to_data:
    add_coords: True
  radius_edge:
    radius: 5

trainer:
  epochs: 10
  batch_size: 1
  learning_rate: 3e-3
  loss: dummy
  eval_metrics: wohoo
  # If val_interval is a float, it is the proportion of training set between validation epochs.
  # If it is an int, it denotes the number of batches in between validation epochs.
  val_interval: 1.0
  log_steps: 1 # How many gradient updates between each log point.
  parallel_engine: ddp
  cuda: {env.device} # Whether to use GPUs.
  gpus: 0 # Number of GPUs to use.
  test: True

callbacks:
  checkpointing:
    checkpoint_freq: 1 # How many epochs we should train for before checkpointing the model.
    save_top_k: 2  # The top k checkpoints with the lowest validation loss will be saved
  roc_curve: True

hydra:
  run:
    dir: logs/${run_name%DATE%TIME}
  sweep:
    dir: logs/${run_name}


defaults:
 logger: wandb
 dataset: sample_dataset
 model: sample_model